{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance Segmentation using YOLO11-seg\n",
    "\n",
    "This notebook demonstrates instance segmentation using Ultralytics YOLO11-seg.\n",
    "\n",
    "**Objectives:**\n",
    "- Precisely delineate pixel-level boundaries of each person\n",
    "- Extract and visualize individual segmentation masks\n",
    "- Calculate mask areas and extract contours/polygons\n",
    "- Export masks in various formats\n",
    "\n",
    "**Model:** YOLO11s-seg (small variant - optimized for CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "# !pip install ultralytics opencv-python matplotlib pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import hsv_to_rgb\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Set up paths\n",
    "PROJECT_ROOT = Path(\"../\")\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"outputs\" / \"segmentations\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO11s-seg model (will download automatically on first run)\n",
    "model = YOLO(\"yolo11s-seg.pt\")\n",
    "\n",
    "# Print model info\n",
    "print(f\"Model: {model.model_name}\")\n",
    "print(f\"Task: {model.task}\")\n",
    "print(f\"\\nThis model can output both bounding boxes AND segmentation masks!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sample images for testing\n",
    "import urllib.request\n",
    "\n",
    "sample_images = {\n",
    "    \"bus.jpg\": \"https://ultralytics.com/images/bus.jpg\",\n",
    "    \"zidane.jpg\": \"https://ultralytics.com/images/zidane.jpg\"\n",
    "}\n",
    "\n",
    "images_dir = DATA_DIR / \"images\"\n",
    "images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for filename, url in sample_images.items():\n",
    "    filepath = images_dir / filename\n",
    "    if not filepath.exists():\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        urllib.request.urlretrieve(url, filepath)\n",
    "        print(f\"  Saved to {filepath}\")\n",
    "    else:\n",
    "        print(f\"{filename} already exists\")\n",
    "\n",
    "print(\"\\nSample images ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Single Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_persons(image_path, model, conf_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Segment persons in an image using YOLO11-seg.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to input image\n",
    "        model: YOLO-seg model instance\n",
    "        conf_threshold: Confidence threshold (0-1)\n",
    "    \n",
    "    Returns:\n",
    "        results: Segmentation results\n",
    "        segments: List of segment dictionaries with masks\n",
    "    \"\"\"\n",
    "    # Run segmentation (class 0 = person in COCO)\n",
    "    results = model.predict(\n",
    "        source=image_path,\n",
    "        classes=[0],  # Only segment persons\n",
    "        conf=conf_threshold,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    segments = []\n",
    "    result = results[0]\n",
    "    \n",
    "    if result.masks is not None:\n",
    "        masks = result.masks.data.cpu().numpy()  # (N, H, W)\n",
    "        boxes = result.boxes\n",
    "        \n",
    "        for i, (mask, box) in enumerate(zip(masks, boxes)):\n",
    "            # Get mask contours\n",
    "            mask_uint8 = (mask * 255).astype(np.uint8)\n",
    "            contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            # Calculate mask area\n",
    "            mask_area = np.sum(mask > 0.5)\n",
    "            \n",
    "            segment = {\n",
    "                \"id\": i,\n",
    "                \"class\": \"person\",\n",
    "                \"confidence\": float(box.conf[0]),\n",
    "                \"bbox_xyxy\": box.xyxy[0].tolist(),\n",
    "                \"mask\": mask,  # Binary mask (H, W)\n",
    "                \"mask_area_pixels\": int(mask_area),\n",
    "                \"contours\": contours\n",
    "            }\n",
    "            segments.append(segment)\n",
    "    \n",
    "    return results, segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run segmentation on sample image\n",
    "image_path = DATA_DIR / \"images\" / \"bus.jpg\"\n",
    "results, segments = segment_persons(image_path, model)\n",
    "\n",
    "print(f\"Segmented {len(segments)} person(s)\")\n",
    "print(\"\\nSegmentation details:\")\n",
    "for seg in segments:\n",
    "    print(f\"  Person {seg['id']}:\")\n",
    "    print(f\"    Confidence: {seg['confidence']:.2f}\")\n",
    "    print(f\"    Mask area: {seg['mask_area_pixels']:,} pixels\")\n",
    "    print(f\"    Contours: {len(seg['contours'])} polygon(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display segmentation results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Original image\n",
    "original = cv2.imread(str(image_path))\n",
    "original = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
    "axes[0].imshow(original)\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "# YOLO annotated output (boxes + masks)\n",
    "annotated = results[0].plot()\n",
    "annotated = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "axes[1].imshow(annotated)\n",
    "axes[1].set_title(f\"YOLO Segmentation: {len(segments)} person(s)\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Individual masks visualization\n",
    "combined_mask = np.zeros((*original.shape[:2], 3), dtype=np.float32)\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, max(len(segments), 1)))[:, :3]\n",
    "\n",
    "for i, seg in enumerate(segments):\n",
    "    mask = seg['mask']\n",
    "    color = colors[i % len(colors)]\n",
    "    for c in range(3):\n",
    "        combined_mask[:, :, c] += mask * color[c]\n",
    "\n",
    "# Blend with original\n",
    "blended = (original / 255.0 * 0.5 + combined_mask * 0.5)\n",
    "blended = np.clip(blended, 0, 1)\n",
    "axes[2].imshow(blended)\n",
    "axes[2].set_title(\"Individual Masks (Color-coded)\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"segmentation_overview.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mask Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mask_info(segment, original_shape):\n",
    "    \"\"\"\n",
    "    Extract detailed information from a segmentation mask.\n",
    "    \n",
    "    Args:\n",
    "        segment: Segment dictionary with mask\n",
    "        original_shape: Shape of original image (H, W, C)\n",
    "    \n",
    "    Returns:\n",
    "        info: Dictionary with mask information\n",
    "    \"\"\"\n",
    "    mask = segment['mask']\n",
    "    \n",
    "    # Calculate centroid\n",
    "    coords = np.argwhere(mask > 0.5)\n",
    "    if len(coords) > 0:\n",
    "        centroid_y = np.mean(coords[:, 0])\n",
    "        centroid_x = np.mean(coords[:, 1])\n",
    "    else:\n",
    "        centroid_y = centroid_x = 0\n",
    "    \n",
    "    # Calculate bounding box from mask\n",
    "    if len(coords) > 0:\n",
    "        y_min, x_min = coords.min(axis=0)\n",
    "        y_max, x_max = coords.max(axis=0)\n",
    "    else:\n",
    "        y_min = x_min = y_max = x_max = 0\n",
    "    \n",
    "    # Calculate area percentage\n",
    "    total_pixels = original_shape[0] * original_shape[1]\n",
    "    area_percentage = (segment['mask_area_pixels'] / total_pixels) * 100\n",
    "    \n",
    "    # Get polygon points from largest contour\n",
    "    polygon_points = []\n",
    "    if segment['contours']:\n",
    "        largest_contour = max(segment['contours'], key=cv2.contourArea)\n",
    "        # Simplify contour\n",
    "        epsilon = 0.01 * cv2.arcLength(largest_contour, True)\n",
    "        approx = cv2.approxPolyDP(largest_contour, epsilon, True)\n",
    "        polygon_points = approx.reshape(-1, 2).tolist()\n",
    "    \n",
    "    return {\n",
    "        \"id\": segment['id'],\n",
    "        \"mask_area_pixels\": segment['mask_area_pixels'],\n",
    "        \"area_percentage\": area_percentage,\n",
    "        \"centroid\": (centroid_x, centroid_y),\n",
    "        \"mask_bbox\": (x_min, y_min, x_max, y_max),\n",
    "        \"polygon_points\": polygon_points,\n",
    "        \"num_polygon_points\": len(polygon_points)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mask information for all segments\n",
    "original = cv2.imread(str(image_path))\n",
    "mask_infos = []\n",
    "\n",
    "print(\"Mask Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "for seg in segments:\n",
    "    info = extract_mask_info(seg, original.shape)\n",
    "    mask_infos.append(info)\n",
    "    \n",
    "    print(f\"\\nPerson {info['id']}:\")\n",
    "    print(f\"  Area: {info['mask_area_pixels']:,} pixels ({info['area_percentage']:.2f}% of image)\")\n",
    "    print(f\"  Centroid: ({info['centroid'][0]:.1f}, {info['centroid'][1]:.1f})\")\n",
    "    print(f\"  Mask BBox: x=[{info['mask_bbox'][0]}, {info['mask_bbox'][2]}], y=[{info['mask_bbox'][1]}, {info['mask_bbox'][3]}]\")\n",
    "    print(f\"  Polygon: {info['num_polygon_points']} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize contours and centroids\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Image with contours\n",
    "img_contours = original.copy()\n",
    "colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255)]\n",
    "\n",
    "for i, seg in enumerate(segments):\n",
    "    color = colors[i % len(colors)]\n",
    "    cv2.drawContours(img_contours, seg['contours'], -1, color, 2)\n",
    "    \n",
    "    # Draw centroid\n",
    "    info = mask_infos[i]\n",
    "    cx, cy = int(info['centroid'][0]), int(info['centroid'][1])\n",
    "    cv2.circle(img_contours, (cx, cy), 8, color, -1)\n",
    "    cv2.putText(img_contours, f\"P{i}\", (cx + 10, cy), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "img_contours = cv2.cvtColor(img_contours, cv2.COLOR_BGR2RGB)\n",
    "axes[0].imshow(img_contours)\n",
    "axes[0].set_title(\"Contours and Centroids\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Simplified polygons\n",
    "img_polygons = original.copy()\n",
    "for i, info in enumerate(mask_infos):\n",
    "    color = colors[i % len(colors)]\n",
    "    if info['polygon_points']:\n",
    "        pts = np.array(info['polygon_points'], dtype=np.int32)\n",
    "        cv2.polylines(img_polygons, [pts], True, color, 3)\n",
    "\n",
    "img_polygons = cv2.cvtColor(img_polygons, cv2.COLOR_BGR2RGB)\n",
    "axes[1].imshow(img_polygons)\n",
    "axes[1].set_title(\"Simplified Polygons\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"contours_polygons.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Binary Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary_mask(segment, target_shape):\n",
    "    \"\"\"\n",
    "    Create a clean binary mask resized to target shape.\n",
    "    \n",
    "    Args:\n",
    "        segment: Segment dictionary with mask\n",
    "        target_shape: Target shape (H, W)\n",
    "    \n",
    "    Returns:\n",
    "        binary_mask: Binary mask (0 or 255)\n",
    "    \"\"\"\n",
    "    mask = segment['mask']\n",
    "    \n",
    "    # Resize if needed\n",
    "    if mask.shape[:2] != target_shape:\n",
    "        mask = cv2.resize(mask.astype(np.float32), (target_shape[1], target_shape[0]))\n",
    "    \n",
    "    # Convert to binary\n",
    "    binary_mask = (mask > 0.5).astype(np.uint8) * 255\n",
    "    \n",
    "    return binary_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display individual binary masks\n",
    "n_persons = len(segments)\n",
    "if n_persons > 0:\n",
    "    fig, axes = plt.subplots(1, n_persons + 1, figsize=(4 * (n_persons + 1), 4))\n",
    "    if n_persons == 1:\n",
    "        axes = [axes, axes]  # Handle single person case\n",
    "    \n",
    "    # Original image\n",
    "    original_rgb = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
    "    axes[0].imshow(original_rgb)\n",
    "    axes[0].set_title(\"Original\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Individual masks\n",
    "    for i, seg in enumerate(segments):\n",
    "        binary_mask = create_binary_mask(seg, original.shape[:2])\n",
    "        axes[i + 1].imshow(binary_mask, cmap='gray')\n",
    "        axes[i + 1].set_title(f\"Person {i} Mask\")\n",
    "        axes[i + 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / \"binary_masks.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No persons detected to create masks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Video Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_segmentation(video_path, model, output_path, conf_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Process video with instance segmentation.\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to input video\n",
    "        model: YOLO-seg model instance\n",
    "        output_path: Path to save output video\n",
    "        conf_threshold: Confidence threshold\n",
    "    \n",
    "    Returns:\n",
    "        frame_stats: List of frame statistics\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Could not open video: {video_path}\")\n",
    "    \n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"Processing video: {video_path}\")\n",
    "    print(f\"  {width}x{height} @ {fps}fps, {total_frames} frames\")\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))\n",
    "    \n",
    "    frame_stats = []\n",
    "    \n",
    "    for frame_idx in tqdm(range(total_frames), desc=\"Segmenting frames\"):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Run segmentation\n",
    "        results = model.predict(\n",
    "            source=frame,\n",
    "            classes=[0],\n",
    "            conf=conf_threshold,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Get annotated frame\n",
    "        annotated = results[0].plot()\n",
    "        out.write(annotated)\n",
    "        \n",
    "        # Collect stats\n",
    "        num_persons = 0\n",
    "        total_mask_area = 0\n",
    "        if results[0].masks is not None:\n",
    "            num_persons = len(results[0].masks)\n",
    "            masks = results[0].masks.data.cpu().numpy()\n",
    "            total_mask_area = sum(np.sum(m > 0.5) for m in masks)\n",
    "        \n",
    "        frame_stats.append({\n",
    "            \"frame\": frame_idx,\n",
    "            \"num_persons\": num_persons,\n",
    "            \"total_mask_area\": total_mask_area\n",
    "        })\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Output saved to: {output_path}\")\n",
    "    return frame_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for available videos\n",
    "video_dir = DATA_DIR / \"videos\"\n",
    "video_extensions = [\".mp4\", \".avi\", \".mov\", \".mkv\"]\n",
    "videos = [f for f in video_dir.iterdir() if f.suffix.lower() in video_extensions] if video_dir.exists() else []\n",
    "\n",
    "if videos:\n",
    "    print(f\"Found {len(videos)} video(s). Processing first one...\")\n",
    "    video_path = videos[0]\n",
    "    output_path = OUTPUT_DIR / f\"{video_path.stem}_segmented.mp4\"\n",
    "    \n",
    "    frame_stats = process_video_segmentation(video_path, model, output_path)\n",
    "    \n",
    "    # Plot statistics\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "    \n",
    "    frames = [s['frame'] for s in frame_stats]\n",
    "    counts = [s['num_persons'] for s in frame_stats]\n",
    "    areas = [s['total_mask_area'] for s in frame_stats]\n",
    "    \n",
    "    axes[0].plot(frames, counts, 'b-')\n",
    "    axes[0].fill_between(frames, counts, alpha=0.3)\n",
    "    axes[0].set_xlabel('Frame')\n",
    "    axes[0].set_ylabel('Number of Persons')\n",
    "    axes[0].set_title('Person Count per Frame')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].plot(frames, areas, 'g-')\n",
    "    axes[1].fill_between(frames, areas, alpha=0.3, color='green')\n",
    "    axes[1].set_xlabel('Frame')\n",
    "    axes[1].set_ylabel('Total Mask Area (pixels)')\n",
    "    axes[1].set_title('Total Segmentation Area per Frame')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / \"video_segmentation_stats.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No videos found. Add video files to data/videos/ to test video segmentation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_masks(segments, original_shape, output_dir, base_name=\"mask\"):\n",
    "    \"\"\"\n",
    "    Export individual masks as PNG files and coordinates as JSON.\n",
    "    \n",
    "    Args:\n",
    "        segments: List of segment dictionaries\n",
    "        original_shape: Shape of original image (H, W, C)\n",
    "        output_dir: Directory to save outputs\n",
    "        base_name: Base name for output files\n",
    "    \n",
    "    Returns:\n",
    "        export_info: Dictionary with export information\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    masks_dir = output_dir / \"individual_masks\"\n",
    "    masks_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    export_info = {\n",
    "        \"image_shape\": list(original_shape),\n",
    "        \"num_persons\": len(segments),\n",
    "        \"masks\": []\n",
    "    }\n",
    "    \n",
    "    for i, seg in enumerate(segments):\n",
    "        # Save binary mask as PNG\n",
    "        binary_mask = create_binary_mask(seg, original_shape[:2])\n",
    "        mask_path = masks_dir / f\"{base_name}_person_{i}.png\"\n",
    "        cv2.imwrite(str(mask_path), binary_mask)\n",
    "        \n",
    "        # Save mask with alpha channel (RGBA)\n",
    "        rgba_mask = np.zeros((original_shape[0], original_shape[1], 4), dtype=np.uint8)\n",
    "        rgba_mask[:, :, :3] = 255  # White foreground\n",
    "        rgba_mask[:, :, 3] = binary_mask  # Alpha from mask\n",
    "        rgba_path = masks_dir / f\"{base_name}_person_{i}_rgba.png\"\n",
    "        cv2.imwrite(str(rgba_path), rgba_mask)\n",
    "        \n",
    "        # Get mask info\n",
    "        info = extract_mask_info(seg, original_shape)\n",
    "        \n",
    "        mask_data = {\n",
    "            \"id\": i,\n",
    "            \"mask_file\": str(mask_path.name),\n",
    "            \"rgba_file\": str(rgba_path.name),\n",
    "            \"confidence\": seg['confidence'],\n",
    "            \"area_pixels\": info['mask_area_pixels'],\n",
    "            \"area_percentage\": info['area_percentage'],\n",
    "            \"centroid\": info['centroid'],\n",
    "            \"bbox\": info['mask_bbox'],\n",
    "            \"polygon\": info['polygon_points']\n",
    "        }\n",
    "        export_info[\"masks\"].append(mask_data)\n",
    "    \n",
    "    # Save JSON\n",
    "    json_path = output_dir / f\"{base_name}_info.json\"\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(export_info, f, indent=2)\n",
    "    \n",
    "    print(f\"Exported {len(segments)} masks to {masks_dir}\")\n",
    "    print(f\"Mask info saved to {json_path}\")\n",
    "    \n",
    "    return export_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export masks from the sample image\n",
    "export_info = export_masks(\n",
    "    segments=segments,\n",
    "    original_shape=original.shape,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    base_name=\"bus\"\n",
    ")\n",
    "\n",
    "# Display export summary\n",
    "print(\"\\nExport Summary:\")\n",
    "print(f\"  Image shape: {export_info['image_shape']}\")\n",
    "print(f\"  Persons exported: {export_info['num_persons']}\")\n",
    "for mask in export_info['masks']:\n",
    "    print(f\"\\n  Person {mask['id']}:\")\n",
    "    print(f\"    Files: {mask['mask_file']}, {mask['rgba_file']}\")\n",
    "    print(f\"    Area: {mask['area_pixels']:,} pixels ({mask['area_percentage']:.2f}%)\")\n",
    "    print(f\"    Polygon: {len(mask['polygon'])} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cutout Person (Background Removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutout_person(image, segment, padding=10):\n",
    "    \"\"\"\n",
    "    Extract a person from the image using their segmentation mask.\n",
    "    \n",
    "    Args:\n",
    "        image: Original image (BGR)\n",
    "        segment: Segment dictionary with mask\n",
    "        padding: Padding around bounding box\n",
    "    \n",
    "    Returns:\n",
    "        cutout: RGBA image with transparent background\n",
    "    \"\"\"\n",
    "    mask = segment['mask']\n",
    "    \n",
    "    # Resize mask to image size if needed\n",
    "    if mask.shape[:2] != image.shape[:2]:\n",
    "        mask = cv2.resize(mask.astype(np.float32), (image.shape[1], image.shape[0]))\n",
    "    \n",
    "    # Create binary mask\n",
    "    binary_mask = (mask > 0.5).astype(np.uint8) * 255\n",
    "    \n",
    "    # Create RGBA image\n",
    "    bgr = image.copy()\n",
    "    rgba = cv2.cvtColor(bgr, cv2.COLOR_BGR2BGRA)\n",
    "    rgba[:, :, 3] = binary_mask\n",
    "    \n",
    "    # Crop to bounding box with padding\n",
    "    bbox = segment['bbox_xyxy']\n",
    "    x1 = max(0, int(bbox[0]) - padding)\n",
    "    y1 = max(0, int(bbox[1]) - padding)\n",
    "    x2 = min(image.shape[1], int(bbox[2]) + padding)\n",
    "    y2 = min(image.shape[0], int(bbox[3]) + padding)\n",
    "    \n",
    "    cutout = rgba[y1:y2, x1:x2]\n",
    "    \n",
    "    return cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cutouts for all detected persons\n",
    "if segments:\n",
    "    fig, axes = plt.subplots(1, len(segments) + 1, figsize=(4 * (len(segments) + 1), 6))\n",
    "    if len(segments) == 1:\n",
    "        axes = [axes, axes]\n",
    "    \n",
    "    # Original\n",
    "    axes[0].imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title(\"Original\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Cutouts\n",
    "    cutouts_dir = OUTPUT_DIR / \"cutouts\"\n",
    "    cutouts_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for i, seg in enumerate(segments):\n",
    "        cutout = cutout_person(original, seg)\n",
    "        \n",
    "        # Save cutout\n",
    "        cutout_path = cutouts_dir / f\"person_{i}_cutout.png\"\n",
    "        cv2.imwrite(str(cutout_path), cutout)\n",
    "        \n",
    "        # Display (convert BGRA to RGBA for matplotlib)\n",
    "        cutout_rgb = cv2.cvtColor(cutout, cv2.COLOR_BGRA2RGBA)\n",
    "        axes[i + 1].imshow(cutout_rgb)\n",
    "        axes[i + 1].set_title(f\"Person {i} Cutout\")\n",
    "        axes[i + 1].axis('off')\n",
    "        axes[i + 1].set_facecolor('lightgray')  # Show transparency\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / \"cutouts_preview.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"\\nCutouts saved to {cutouts_dir}\")\n",
    "else:\n",
    "    print(\"No persons detected to create cutouts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. **Model Loading**: Using YOLO11s-seg for instance segmentation\n",
    "2. **Single Image Segmentation**: Extracting person masks\n",
    "3. **Mask Operations**: Calculating areas, contours, and polygons\n",
    "4. **Binary Masks**: Creating clean binary masks\n",
    "5. **Video Segmentation**: Processing video with frame statistics\n",
    "6. **Mask Export**: Saving masks as PNG and coordinates as JSON\n",
    "7. **Cutouts**: Background removal for individual persons\n",
    "\n",
    "**Next Steps:**\n",
    "- Try `03_person_counting.ipynb` for counting and crowd analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
