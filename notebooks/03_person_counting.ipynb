{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Person Counting using YOLO11\n",
    "\n",
    "This notebook demonstrates person counting using Ultralytics YOLO11.\n",
    "\n",
    "**Objectives:**\n",
    "- Aggregate detection results to provide accurate headcount\n",
    "- Implement zone-based counting with ROI regions\n",
    "- Generate counting statistics for videos\n",
    "- Create crowd density estimation and heatmaps\n",
    "\n",
    "**Model:** YOLO11s (small variant - optimized for CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "# !pip install ultralytics opencv-python matplotlib pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Set up paths\n",
    "PROJECT_ROOT = Path(\"../\")\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"outputs\" / \"counting\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO11s model\n",
    "model = YOLO(\"yolo11s.pt\")\n",
    "\n",
    "print(f\"Model: {model.model_name}\")\n",
    "print(f\"Task: {model.task}\")\n",
    "print(f\"Person class ID: 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sample images for testing\n",
    "import urllib.request\n",
    "\n",
    "sample_images = {\n",
    "    \"bus.jpg\": \"https://ultralytics.com/images/bus.jpg\",\n",
    "    \"zidane.jpg\": \"https://ultralytics.com/images/zidane.jpg\"\n",
    "}\n",
    "\n",
    "images_dir = DATA_DIR / \"images\"\n",
    "images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for filename, url in sample_images.items():\n",
    "    filepath = images_dir / filename\n",
    "    if not filepath.exists():\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        urllib.request.urlretrieve(url, filepath)\n",
    "    else:\n",
    "        print(f\"{filename} already exists\")\n",
    "\n",
    "print(\"\\nSample images ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simple Frame Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_persons(image_source, model, conf_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Count persons in an image.\n",
    "    \n",
    "    Args:\n",
    "        image_source: Path to image or image array\n",
    "        model: YOLO model instance\n",
    "        conf_threshold: Confidence threshold\n",
    "    \n",
    "    Returns:\n",
    "        count: Number of persons detected\n",
    "        results: Detection results\n",
    "        details: List of detection details\n",
    "    \"\"\"\n",
    "    results = model.predict(\n",
    "        source=image_source,\n",
    "        classes=[0],  # Person class only\n",
    "        conf=conf_threshold,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    count = len(results[0].boxes)\n",
    "    \n",
    "    details = []\n",
    "    for i, box in enumerate(results[0].boxes):\n",
    "        details.append({\n",
    "            \"id\": i,\n",
    "            \"confidence\": float(box.conf[0]),\n",
    "            \"bbox\": box.xyxy[0].tolist(),\n",
    "            \"center\": ((box.xyxy[0][0] + box.xyxy[0][2]) / 2,\n",
    "                       (box.xyxy[0][1] + box.xyxy[0][3]) / 2)\n",
    "        })\n",
    "    \n",
    "    return count, results, details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count persons in sample image\n",
    "image_path = DATA_DIR / \"images\" / \"bus.jpg\"\n",
    "count, results, details = count_persons(image_path, model)\n",
    "\n",
    "print(f\"Image: {image_path.name}\")\n",
    "print(f\"Persons detected: {count}\")\n",
    "print(\"\\nDetection details:\")\n",
    "for det in details:\n",
    "    print(f\"  Person {det['id']}: confidence={det['confidence']:.2f}, center=({det['center'][0]:.0f}, {det['center'][1]:.0f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_count_overlay(image, count, position=\"top-left\", font_scale=1.5):\n",
    "    \"\"\"\n",
    "    Draw person count overlay on image.\n",
    "    \n",
    "    Args:\n",
    "        image: Image array (BGR)\n",
    "        count: Person count\n",
    "        position: Position of overlay (\"top-left\", \"top-right\", \"bottom-left\", \"bottom-right\")\n",
    "        font_scale: Font size scale\n",
    "    \n",
    "    Returns:\n",
    "        image: Image with overlay\n",
    "    \"\"\"\n",
    "    img = image.copy()\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    text = f\"Count: {count}\"\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    thickness = 3\n",
    "    \n",
    "    # Get text size\n",
    "    (text_w, text_h), baseline = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "    \n",
    "    # Calculate position\n",
    "    padding = 15\n",
    "    if position == \"top-left\":\n",
    "        x, y = padding, text_h + padding\n",
    "    elif position == \"top-right\":\n",
    "        x, y = w - text_w - padding, text_h + padding\n",
    "    elif position == \"bottom-left\":\n",
    "        x, y = padding, h - padding\n",
    "    else:  # bottom-right\n",
    "        x, y = w - text_w - padding, h - padding\n",
    "    \n",
    "    # Draw background rectangle\n",
    "    cv2.rectangle(img, (x - 10, y - text_h - 10), (x + text_w + 10, y + 10), (0, 0, 0), -1)\n",
    "    cv2.rectangle(img, (x - 10, y - text_h - 10), (x + text_w + 10, y + 10), (0, 255, 0), 2)\n",
    "    \n",
    "    # Draw text\n",
    "    cv2.putText(img, text, (x, y), font, font_scale, (0, 255, 0), thickness)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image with count overlay\n",
    "original = cv2.imread(str(image_path))\n",
    "annotated = results[0].plot()\n",
    "with_count = draw_count_overlay(annotated, count)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "axes[0].imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(with_count, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title(f\"Person Count: {count}\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"simple_count.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Zone-Based Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_in_polygon(point, polygon):\n",
    "    \"\"\"\n",
    "    Check if a point is inside a polygon using ray casting.\n",
    "    \n",
    "    Args:\n",
    "        point: (x, y) tuple\n",
    "        polygon: List of (x, y) tuples defining the polygon\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if point is inside polygon\n",
    "    \"\"\"\n",
    "    x, y = point\n",
    "    n = len(polygon)\n",
    "    inside = False\n",
    "    \n",
    "    p1x, p1y = polygon[0]\n",
    "    for i in range(1, n + 1):\n",
    "        p2x, p2y = polygon[i % n]\n",
    "        if y > min(p1y, p2y):\n",
    "            if y <= max(p1y, p2y):\n",
    "                if x <= max(p1x, p2x):\n",
    "                    if p1y != p2y:\n",
    "                        xinters = (y - p1y) * (p2x - p1x) / (p2y - p1y) + p1x\n",
    "                    if p1x == p2x or x <= xinters:\n",
    "                        inside = not inside\n",
    "        p1x, p1y = p2x, p2y\n",
    "    \n",
    "    return inside\n",
    "\n",
    "\n",
    "def count_in_zones(image_source, model, zones, conf_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Count persons in defined zones.\n",
    "    \n",
    "    Args:\n",
    "        image_source: Path to image or image array\n",
    "        model: YOLO model instance\n",
    "        zones: Dictionary of zone_name: polygon_points\n",
    "        conf_threshold: Confidence threshold\n",
    "    \n",
    "    Returns:\n",
    "        zone_counts: Dictionary of zone_name: count\n",
    "        results: Detection results\n",
    "        person_zones: List of (person_id, zone_name or None)\n",
    "    \"\"\"\n",
    "    # Run detection\n",
    "    results = model.predict(\n",
    "        source=image_source,\n",
    "        classes=[0],\n",
    "        conf=conf_threshold,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    zone_counts = {name: 0 for name in zones.keys()}\n",
    "    zone_counts['outside'] = 0\n",
    "    person_zones = []\n",
    "    \n",
    "    for i, box in enumerate(results[0].boxes):\n",
    "        # Get center point of bounding box\n",
    "        bbox = box.xyxy[0]\n",
    "        center_x = (bbox[0] + bbox[2]) / 2\n",
    "        center_y = (bbox[1] + bbox[3]) / 2\n",
    "        center = (float(center_x), float(center_y))\n",
    "        \n",
    "        # Check which zone the person is in\n",
    "        person_zone = None\n",
    "        for zone_name, polygon in zones.items():\n",
    "            if point_in_polygon(center, polygon):\n",
    "                zone_counts[zone_name] += 1\n",
    "                person_zone = zone_name\n",
    "                break\n",
    "        \n",
    "        if person_zone is None:\n",
    "            zone_counts['outside'] += 1\n",
    "            person_zone = 'outside'\n",
    "        \n",
    "        person_zones.append((i, person_zone))\n",
    "    \n",
    "    return zone_counts, results, person_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define counting zones (as percentages of image dimensions for flexibility)\n",
    "# Load image to get dimensions\n",
    "img = cv2.imread(str(image_path))\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "# Define zones (coordinates as percentages, will be converted to pixels)\n",
    "zones_pct = {\n",
    "    \"Zone A (Left)\": [(0.0, 0.0), (0.4, 0.0), (0.4, 1.0), (0.0, 1.0)],\n",
    "    \"Zone B (Right)\": [(0.4, 0.0), (1.0, 0.0), (1.0, 1.0), (0.4, 1.0)]\n",
    "}\n",
    "\n",
    "# Convert to pixel coordinates\n",
    "zones = {}\n",
    "for name, pct_points in zones_pct.items():\n",
    "    zones[name] = [(int(x * w), int(y * h)) for x, y in pct_points]\n",
    "\n",
    "print(\"Defined zones:\")\n",
    "for name, points in zones.items():\n",
    "    print(f\"  {name}: {points}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count persons in zones\n",
    "zone_counts, results, person_zones = count_in_zones(image_path, model, zones)\n",
    "\n",
    "print(\"\\nZone Counts:\")\n",
    "for zone_name, count in zone_counts.items():\n",
    "    print(f\"  {zone_name}: {count} person(s)\")\n",
    "\n",
    "print(\"\\nPerson Assignments:\")\n",
    "for person_id, zone in person_zones:\n",
    "    print(f\"  Person {person_id}: {zone}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_zones_with_counts(image, zones, zone_counts, results, person_zones):\n",
    "    \"\"\"\n",
    "    Draw zones and counts on image.\n",
    "    \n",
    "    Args:\n",
    "        image: Image array (BGR)\n",
    "        zones: Dictionary of zone_name: polygon_points\n",
    "        zone_counts: Dictionary of zone_name: count\n",
    "        results: Detection results\n",
    "        person_zones: List of (person_id, zone_name)\n",
    "    \n",
    "    Returns:\n",
    "        image: Annotated image\n",
    "    \"\"\"\n",
    "    img = image.copy()\n",
    "    \n",
    "    # Colors for different zones\n",
    "    colors = {\n",
    "        \"Zone A (Left)\": (255, 0, 0),    # Blue\n",
    "        \"Zone B (Right)\": (0, 255, 0),   # Green\n",
    "        \"outside\": (128, 128, 128)       # Gray\n",
    "    }\n",
    "    \n",
    "    # Draw zone polygons\n",
    "    overlay = img.copy()\n",
    "    for zone_name, polygon in zones.items():\n",
    "        color = colors.get(zone_name, (0, 255, 255))\n",
    "        pts = np.array(polygon, dtype=np.int32)\n",
    "        cv2.fillPoly(overlay, [pts], color)\n",
    "    \n",
    "    # Blend overlay\n",
    "    img = cv2.addWeighted(overlay, 0.2, img, 0.8, 0)\n",
    "    \n",
    "    # Draw zone boundaries\n",
    "    for zone_name, polygon in zones.items():\n",
    "        color = colors.get(zone_name, (0, 255, 255))\n",
    "        pts = np.array(polygon, dtype=np.int32)\n",
    "        cv2.polylines(img, [pts], True, color, 2)\n",
    "    \n",
    "    # Draw detections with zone colors\n",
    "    for i, box in enumerate(results[0].boxes):\n",
    "        # Find zone for this person\n",
    "        zone = next((z for pid, z in person_zones if pid == i), 'outside')\n",
    "        color = colors.get(zone, (128, 128, 128))\n",
    "        \n",
    "        bbox = box.xyxy[0].cpu().numpy().astype(int)\n",
    "        cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)\n",
    "        \n",
    "        # Draw person label\n",
    "        label = f\"P{i}\"\n",
    "        cv2.putText(img, label, (bbox[0], bbox[1] - 5), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "    \n",
    "    # Draw zone count labels\n",
    "    for zone_name, polygon in zones.items():\n",
    "        color = colors.get(zone_name, (0, 255, 255))\n",
    "        # Get center of zone\n",
    "        center_x = int(np.mean([p[0] for p in polygon]))\n",
    "        center_y = int(np.mean([p[1] for p in polygon]))\n",
    "        \n",
    "        count = zone_counts.get(zone_name, 0)\n",
    "        text = f\"{zone_name}: {count}\"\n",
    "        \n",
    "        # Draw background\n",
    "        (text_w, text_h), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n",
    "        cv2.rectangle(img, (center_x - text_w//2 - 5, center_y - text_h - 5),\n",
    "                      (center_x + text_w//2 + 5, center_y + 5), (0, 0, 0), -1)\n",
    "        cv2.putText(img, text, (center_x - text_w//2, center_y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize zone-based counting\n",
    "zone_image = draw_zones_with_counts(img, zones, zone_counts, results, person_zones)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(cv2.cvtColor(zone_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Zone-Based Person Counting\")\n",
    "plt.axis('off')\n",
    "plt.savefig(OUTPUT_DIR / \"zone_counting.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Video Counting with Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_counting(video_path, model, output_path, zones=None, conf_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Process video with person counting.\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to input video\n",
    "        model: YOLO model instance\n",
    "        output_path: Path to save output video\n",
    "        zones: Optional dictionary of zones for zone-based counting\n",
    "        conf_threshold: Confidence threshold\n",
    "    \n",
    "    Returns:\n",
    "        frame_stats: List of per-frame statistics\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Could not open video: {video_path}\")\n",
    "    \n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"Processing: {video_path}\")\n",
    "    print(f\"  Resolution: {width}x{height}\")\n",
    "    print(f\"  FPS: {fps}, Frames: {total_frames}\")\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))\n",
    "    \n",
    "    # Convert zone percentages to pixels if provided\n",
    "    pixel_zones = None\n",
    "    if zones:\n",
    "        pixel_zones = {}\n",
    "        for name, pct_points in zones.items():\n",
    "            pixel_zones[name] = [(int(x * width), int(y * height)) for x, y in pct_points]\n",
    "    \n",
    "    frame_stats = []\n",
    "    \n",
    "    for frame_idx in tqdm(range(total_frames), desc=\"Processing frames\"):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if pixel_zones:\n",
    "            zone_counts, results, person_zones = count_in_zones(frame, model, pixel_zones, conf_threshold)\n",
    "            annotated = draw_zones_with_counts(frame, pixel_zones, zone_counts, results, person_zones)\n",
    "            total_count = sum(zone_counts.values())\n",
    "            \n",
    "            stats = {\n",
    "                \"frame\": frame_idx,\n",
    "                \"total_count\": total_count,\n",
    "                \"zone_counts\": zone_counts.copy()\n",
    "            }\n",
    "        else:\n",
    "            count, results, _ = count_persons(frame, model, conf_threshold)\n",
    "            annotated = results[0].plot()\n",
    "            annotated = draw_count_overlay(annotated, count)\n",
    "            \n",
    "            stats = {\n",
    "                \"frame\": frame_idx,\n",
    "                \"total_count\": count\n",
    "            }\n",
    "        \n",
    "        frame_stats.append(stats)\n",
    "        out.write(annotated)\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Output saved to: {output_path}\")\n",
    "    return frame_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for available videos\n",
    "video_dir = DATA_DIR / \"videos\"\n",
    "video_extensions = [\".mp4\", \".avi\", \".mov\", \".mkv\"]\n",
    "videos = [f for f in video_dir.iterdir() if f.suffix.lower() in video_extensions] if video_dir.exists() else []\n",
    "\n",
    "if videos:\n",
    "    print(f\"Found {len(videos)} video(s)\")\n",
    "    video_path = videos[0]\n",
    "    output_path = OUTPUT_DIR / f\"{video_path.stem}_counted.mp4\"\n",
    "    \n",
    "    # Define zones for video (using percentages)\n",
    "    video_zones = {\n",
    "        \"Zone A\": [(0.0, 0.0), (0.5, 0.0), (0.5, 1.0), (0.0, 1.0)],\n",
    "        \"Zone B\": [(0.5, 0.0), (1.0, 0.0), (1.0, 1.0), (0.5, 1.0)]\n",
    "    }\n",
    "    \n",
    "    frame_stats = process_video_counting(\n",
    "        video_path=video_path,\n",
    "        model=model,\n",
    "        output_path=output_path,\n",
    "        zones=video_zones,\n",
    "        conf_threshold=0.25\n",
    "    )\n",
    "else:\n",
    "    print(\"No videos found in data/videos/\")\n",
    "    print(\"Creating simulated frame stats for demonstration...\")\n",
    "    \n",
    "    # Simulate frame stats for demonstration\n",
    "    np.random.seed(42)\n",
    "    frame_stats = []\n",
    "    for i in range(100):\n",
    "        base_count = 5 + np.sin(i / 10) * 3\n",
    "        noise = np.random.normal(0, 1)\n",
    "        total = max(0, int(base_count + noise))\n",
    "        frame_stats.append({\n",
    "            \"frame\": i,\n",
    "            \"total_count\": total,\n",
    "            \"zone_counts\": {\n",
    "                \"Zone A\": max(0, int(total * 0.4 + np.random.normal(0, 0.5))),\n",
    "                \"Zone B\": max(0, int(total * 0.6 + np.random.normal(0, 0.5)))\n",
    "            }\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze and visualize counting statistics\n",
    "frames = [s['frame'] for s in frame_stats]\n",
    "counts = [s['total_count'] for s in frame_stats]\n",
    "\n",
    "# Calculate statistics\n",
    "min_count = min(counts)\n",
    "max_count = max(counts)\n",
    "avg_count = np.mean(counts)\n",
    "std_count = np.std(counts)\n",
    "\n",
    "print(\"Counting Statistics:\")\n",
    "print(f\"  Min: {min_count}\")\n",
    "print(f\"  Max: {max_count}\")\n",
    "print(f\"  Average: {avg_count:.2f}\")\n",
    "print(f\"  Std Dev: {std_count:.2f}\")\n",
    "print(f\"  Total frames: {len(frames)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot count over time\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Total count over time\n",
    "axes[0, 0].plot(frames, counts, 'b-', linewidth=1, alpha=0.7)\n",
    "axes[0, 0].fill_between(frames, counts, alpha=0.3)\n",
    "axes[0, 0].axhline(avg_count, color='r', linestyle='--', label=f'Average: {avg_count:.1f}')\n",
    "axes[0, 0].set_xlabel('Frame')\n",
    "axes[0, 0].set_ylabel('Person Count')\n",
    "axes[0, 0].set_title('Person Count Over Time')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Zone comparison (if zones were used)\n",
    "if 'zone_counts' in frame_stats[0]:\n",
    "    zone_names = list(frame_stats[0]['zone_counts'].keys())\n",
    "    for zone_name in zone_names:\n",
    "        if zone_name != 'outside':\n",
    "            zone_counts_list = [s['zone_counts'].get(zone_name, 0) for s in frame_stats]\n",
    "            axes[0, 1].plot(frames, zone_counts_list, label=zone_name, alpha=0.7)\n",
    "    axes[0, 1].set_xlabel('Frame')\n",
    "    axes[0, 1].set_ylabel('Person Count')\n",
    "    axes[0, 1].set_title('Zone-wise Count Over Time')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "else:\n",
    "    axes[0, 1].text(0.5, 0.5, 'No zone data', ha='center', va='center')\n",
    "\n",
    "# Histogram of counts\n",
    "axes[1, 0].hist(counts, bins=max(10, max_count - min_count + 1), edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].axvline(avg_count, color='r', linestyle='--', label=f'Average: {avg_count:.1f}')\n",
    "axes[1, 0].set_xlabel('Person Count')\n",
    "axes[1, 0].set_ylabel('Frequency (Frames)')\n",
    "axes[1, 0].set_title('Distribution of Person Counts')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Summary statistics box\n",
    "stats_text = f\"\"\"Summary Statistics\n",
    "─────────────────\n",
    "Min Count: {min_count}\n",
    "Max Count: {max_count}\n",
    "Average: {avg_count:.2f}\n",
    "Std Dev: {std_count:.2f}\n",
    "Total Frames: {len(frames)}\"\"\"\n",
    "\n",
    "axes[1, 1].text(0.1, 0.5, stats_text, fontfamily='monospace', fontsize=12,\n",
    "                verticalalignment='center', transform=axes[1, 1].transAxes)\n",
    "axes[1, 1].axis('off')\n",
    "axes[1, 1].set_title('Statistics Summary')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"counting_statistics.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Crowd Density Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_density_map(image_shape, detections, kernel_size=50):\n",
    "    \"\"\"\n",
    "    Create a density heatmap from person detections.\n",
    "    \n",
    "    Args:\n",
    "        image_shape: (H, W) tuple of image dimensions\n",
    "        detections: List of detection dictionaries with 'center' key\n",
    "        kernel_size: Size of Gaussian kernel for smoothing\n",
    "    \n",
    "    Returns:\n",
    "        density_map: 2D density array\n",
    "    \"\"\"\n",
    "    h, w = image_shape[:2]\n",
    "    density_map = np.zeros((h, w), dtype=np.float32)\n",
    "    \n",
    "    for det in detections:\n",
    "        cx, cy = int(det['center'][0]), int(det['center'][1])\n",
    "        if 0 <= cx < w and 0 <= cy < h:\n",
    "            density_map[cy, cx] = 1.0\n",
    "    \n",
    "    # Apply Gaussian blur for smooth density\n",
    "    if kernel_size > 0:\n",
    "        density_map = cv2.GaussianBlur(density_map, (kernel_size * 2 + 1, kernel_size * 2 + 1), kernel_size)\n",
    "    \n",
    "    # Normalize\n",
    "    if density_map.max() > 0:\n",
    "        density_map = density_map / density_map.max()\n",
    "    \n",
    "    return density_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_density_heatmap_overlay(image, density_map, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Overlay density heatmap on image.\n",
    "    \n",
    "    Args:\n",
    "        image: Original image (BGR)\n",
    "        density_map: 2D density array\n",
    "        alpha: Transparency of overlay\n",
    "    \n",
    "    Returns:\n",
    "        overlay: Image with heatmap overlay\n",
    "    \"\"\"\n",
    "    # Convert density to colormap\n",
    "    density_uint8 = (density_map * 255).astype(np.uint8)\n",
    "    heatmap = cv2.applyColorMap(density_uint8, cv2.COLORMAP_JET)\n",
    "    \n",
    "    # Blend with original image\n",
    "    overlay = cv2.addWeighted(image, 1 - alpha, heatmap, alpha, 0)\n",
    "    \n",
    "    return overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create density heatmap for sample image\n",
    "image = cv2.imread(str(image_path))\n",
    "count, results, details = count_persons(image_path, model)\n",
    "\n",
    "# Calculate density map\n",
    "density_map = calculate_density_map(image.shape, details, kernel_size=80)\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Original with detections\n",
    "annotated = results[0].plot()\n",
    "axes[0].imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title(f\"Detections: {count} persons\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Density map\n",
    "im = axes[1].imshow(density_map, cmap='jet', vmin=0, vmax=1)\n",
    "axes[1].set_title(\"Crowd Density Map\")\n",
    "axes[1].axis('off')\n",
    "plt.colorbar(im, ax=axes[1], label='Density')\n",
    "\n",
    "# Overlay\n",
    "overlay = create_density_heatmap_overlay(image, density_map, alpha=0.4)\n",
    "axes[2].imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "axes[2].set_title(\"Density Heatmap Overlay\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"density_heatmap.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Counting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export frame statistics to CSV\n",
    "if frame_stats:\n",
    "    # Create DataFrame\n",
    "    df_data = []\n",
    "    for stat in frame_stats:\n",
    "        row = {\n",
    "            'frame': stat['frame'],\n",
    "            'total_count': stat['total_count']\n",
    "        }\n",
    "        if 'zone_counts' in stat:\n",
    "            for zone_name, count in stat['zone_counts'].items():\n",
    "                row[f'count_{zone_name}'] = count\n",
    "        df_data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(df_data)\n",
    "    csv_path = OUTPUT_DIR / \"counting_results.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Results saved to: {csv_path}\")\n",
    "    print(f\"\\nDataFrame preview:\")\n",
    "    display(df.head(10))\n",
    "    \n",
    "    # Export summary statistics\n",
    "    summary = {\n",
    "        \"total_frames\": len(frame_stats),\n",
    "        \"min_count\": min_count,\n",
    "        \"max_count\": max_count,\n",
    "        \"average_count\": float(avg_count),\n",
    "        \"std_dev\": float(std_count)\n",
    "    }\n",
    "    \n",
    "    json_path = OUTPUT_DIR / \"counting_summary.json\"\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(f\"\\nSummary saved to: {json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Interactive Counting (Custom Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Count persons in a custom image\n",
    "# Uncomment and modify the path below:\n",
    "\n",
    "# custom_image = \"/path/to/your/image.jpg\"\n",
    "# count, results, details = count_persons(custom_image, model)\n",
    "# \n",
    "# print(f\"Persons detected: {count}\")\n",
    "# \n",
    "# # Show with count overlay\n",
    "# img = cv2.imread(custom_image)\n",
    "# annotated = results[0].plot()\n",
    "# with_overlay = draw_count_overlay(annotated, count)\n",
    "# \n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.imshow(cv2.cvtColor(with_overlay, cv2.COLOR_BGR2RGB))\n",
    "# plt.title(f\"Person Count: {count}\")\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. **Simple Counting**: Basic person count per image/frame\n",
    "2. **Zone-Based Counting**: Counting within defined ROI regions\n",
    "3. **Video Counting**: Frame-by-frame counting with statistics\n",
    "4. **Crowd Density**: Heatmap visualization of crowd distribution\n",
    "5. **Statistics Export**: CSV and JSON export of counting results\n",
    "\n",
    "**Key Features:**\n",
    "- Zone polygon support for area-specific counting\n",
    "- Statistical analysis (min, max, average, std dev)\n",
    "- Density heatmap generation\n",
    "- Multiple output formats (video, CSV, JSON, images)\n",
    "\n",
    "**Next Steps:**\n",
    "- Integrate with multi-object tracking for counting unique individuals\n",
    "- Add line-crossing counting for entrance/exit monitoring\n",
    "- Implement real-time counting from webcam stream"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
